Starting code feedback for Shiyuan, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 12.43 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: .git, CMEEminiproject, week7, week3, week2, Feedback, HPC, week1

Found the following files in parent directory: README.md, .gitignore

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:

**********************************************************************
*~ 
*.tmp
*.log
__pycache__
*/sandbox
**/results/*
!**/results/.gitkeep
**/sandbox/*
!**/sandbox/.gitkeep
**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
# My CMEECoursework Repository

## Description

This repository contains all CMEE coursework files.

## Languages

Python, R, Jupyter, Latex, Shell

**Installation:**

To use scripts in this directory clone the repository.

```bash
git clone git@github.com:shiyuan-huang22/CMEECourseWork.git
```

## Project structure and Usage 

Please check weekly README.md 

## Author name and contact

Name: Shiyuan Huang

Email: sh422@ic.ac.uk

**********************************************************************

======================================================================
Looking for the weekly directories...

Found 4 weekly directories: week1, week2, week3, week7

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: code, results, data

Found the following files: README.md, .gitignore

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
# Computing Week 3

## Description

This directory contains all R scripts for coursework week3

## Languages

R

## Dependencies

For some scripts in this directory, packages [tidyverse], [ggplot2], [reshape2], [maps], [dplyer], [broom] are required. 

**Installation:**
```R
install.packages(c("tidyverse", "ggplot2", "reshape2", "maps", "dplyer", "broom"))
```

```

[LaTeX] installation is also required. Please run following **bash** script in Terminal for installation:
```bash
sudo apt install texlive-full texlive-fonts-recommended texlive-pictures texlive-latex-extra imagemagick
```
## Installation

To use scripts in this directory clone the repository.

```bash
git clone git@github.com:shiyuan-huang22/CMEECourseWork.git
```

## Project structure and Usage 
<br/>

### Biological Computing in R:

- **basic_io.R:** A simple script to illustrate the input-output of R.

- **boilerplate.R:** R scripts for demonstrating R functions.

- **Florida.R:** Practical calculations and plots. 

- **Florida.tex:** Source code for the results and interpretation of the practice.

- **TAutoCorr.R:** Answer the question : are temperatures of one year significantly correlated with the next year (successive years), across years in Florida?

- **control_flow.R:** Demonstration control flow tool.

- **Ricker.R:** Runs the Ricker model.

- **sample.R:** An example of vectorisation involving lapply and sapply

- **TreeHeight.R:** Using the trigonometric formula, calculate the height of the tree given the distance and angle from the base to the top of each tree.

- **Vectorize1.py:** This script is the transfered version of `Vectorise1.R`

- **Vectorize2.py:** This script is the translated version of `Vectorise2.py`

- **Vectorize2.R:** Running the stochastic Rick equation with Gaussian fluctuations. 

- **run_vectorized.sh:** A shell script that compares the computational speed of the four scripts: `Vectorize1.R, Vectorize2.R, Vectorize1.py,  Vectorize2.py` .

- **get_TreeHeight.R:** Function to calculate tree height and strip the `.csv`

- **get_TreeHeight.py:** This script is python version of `get_TreeHeight.R`

- **run_get_TreeHeight.sh:** runs `get_TreeHeight.R` and `get_TreeHeight.py` by using `tree.csv` as an argument

<br/>

### Data Management and Visualization: 

- **DataWrang.R**: Data processing of PoundHillData with reshape2 package. 

- **DataWrangTidy.R:** Data manipulation for PoundHillData with tidyverse.

- **Girko.R:** Plot Girko’s law simulation.

- **GPDD_Data.R:** Mapping GPDD.

- **MyBars.R:** Demonstration of plotting annotations. 

- **plotLin.R:** Demonstration of mathematical annotation.

- **PP_Dists.R:** Create three plots, each containing subplots of the distribution of predator mass, prey mass, and prey mass to predator mass size ratio by feeding interaction type. And calculate the mean and median of predator mass, prey mass and predator-prey size ratio by feeding type.

- **PP_Regress.R:** Plot the analysis from the subset of Predator.lifestage and calculate the regression results corresponding to the fitted line. 

- **PP_Regress_loc.R:** Do the same thing as `PP_Regress.R` , but the analysis this time should be separate by the dataset’s Location field.


## Author name and contact

Name: Shiyuan Huang

Email: sh422@ic.ac.uk
**********************************************************************

Results directory is empty - good! 

Found 36 code files: apply2.R, apply1.R, Vectorize2.py, Girko.R, next.R, plotLin.R, Florida.R, sample.R, PP_Dists.R, get_TreeHeight.py, TAutoCorr.tex, try.R, MyBars.R, PP_Regress_loc.R, control_flow.R, TAutoCorr.bib, TAutoCorr.R, Ricker.R, boilerplate.R, run_vectorized.sh, R_conditionals.R, Vectorize1.py, browse.R, GPDD_Data.R, PP_Regress.R, get_TreeHeight.R, Vectorize2.R, DataWrangTidy.R, preallocate.R, break.R, run_get_TreeHeight.sh, DataWrang.R, Florida.tex, TreeHeight.R, basic_io.R, Vectorize1.R

======================================================================
Testing script/code files...

======================================================================
Inspecting script file apply2.R...

File contents are:

**********************************************************************
rm(list = ls())
SomeOperation <- function(v) {
  if (sum(v) > 0) { #note that sum(v) is a single (scalar) value
    return(v * 100)
  } else { 
  return(v)
    }
}

M <- matrix(rnorm(100), 10, 10)
print(apply(M, 1, SomeOperation))
**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 


**********************************************************************
           [,1]       [,2]       [,3]        [,4]        [,5]       [,6]
 [1,] -98.22093  1.0968675 -1.8688169 -0.82745116 -0.59766548 -1.1042375
 [2,]  62.83392 -0.5181062 -1.5239334 -1.26038632 -0.26618318 -0.7593031
 [3,] 149.64774 -0.7368013 -0.7600825 -0.26322891 -0.30871212 -0.6659384
 [4,]  53.62509  0.6381902 -1.7534555  1.38980496  0.41661598  0.7245445
 [5,] 141.73293  1.7163598  0.4493554 -2.87783917  0.73289173 -0.5107045
 [6,]  46.75413 -1.0341999  0.8853213  0.15231827 -0.87240778 -
**********************************************************************

Code ran without errors

Time consumed = 0.19886s

======================================================================
Inspecting script file apply1.R...

File contents are:

**********************************************************************
## Build a random matrix

rm(list = ls())

M <- matrix(rnorm(100), 10, 10)

## Take the mean of each row
RowMeans <- apply(M, 1, mean)
print (RowMeans)

## Now the variance
RowVars <- apply(M, 1, var)
print (RowVars)

## By column
ColMeans <- apply(M, 2, mean)
print(ColMeans)
**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 


**********************************************************************
 [1]  0.17647569  0.03918541 -0.22712314  0.01611788 -0.09327521  0.39651822
 [7]  0.21823963 -0.24792568  0.52098695 -0.33000488
 [1] 0.8091101 0.4968100 1.0253965 1.5580773 1.0276805 1.1059756 1.0282113
 [8] 0.7595473 1.1990788 1.5537232
 [1] -0.19357134 -0.29664595  0.46139337  0.20167167 -0.37473504  0.03129820
 [7]  0.58769593 -0.20429988 -0.04982365  0.30621157

**********************************************************************

Code ran without errors

Time consumed = 0.18340s

======================================================================
Inspecting script file Vectorize2.py...

File contents are:

**********************************************************************
#!/usr/bin/env python3

"""This script is the translated version of Vectorise2.py"""

__appname__ = 'Vectorize2'
__author__ = '01_Awesome_Aardvarks'
__version__ = '0.0.1'
__license__ = 'None'

import numpy as np 
import time

def stochrick(p0 = np.random.uniform(.5, 1.5, 1000), r = 1.2, K = 1, sigma = 0.2, numyears = 100):
    """Runs the stochastic Ricker equation with Gaussian fluctuations"""
    N = np.zeros((numyears, len(p0)))  #initial the empty matrix
    N[0] = p0

    # the loop 
    for pop in range(len(p0)):
        for yr in range(1, numyears):
            N[yr, pop] = N[yr - 1, pop] * np.exp(r * (1 - N[yr - 1, pop] / K) + np.random.normal(0, sigma, 1))
    return N


# Now write another function called stochrickvect that vectorizes the above function
def stochrickvect(p0 = np.random.uniform(.5, 1.5, 1000), r = 1.2, K = 1, sigma = 0.2, numyears = 100):
    """Runs vectorised version of above function"""
    N = np.zeros((numyears, len(p0)))  #same methods
    N[0] = p0 
    for yr in range(1, numyears):
        N[yr, ] = N[yr - 1, ] * np.exp(r * (1 - (N[yr - 1, ] / K)) + np.random.normal(0, sigma, size = 1))
    return N


# time stochrick
start = time.time()
stochrick()
end = time.time()
print("Non-vectorized Stochastic Ricker takes:")
print(end - start)

# time stochrickvect
start = time.time()
stochrickvect()
end = time.time()
print("Vectorized Stochastic Ricker takes:")
print(end - start)

print("vectorise2.py is done")
**********************************************************************

Testing Vectorize2.py...

Vectorize2.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 100

Output (only first 500 characters): 


**********************************************************************
Non-vectorized Stochastic Ricker takes:
0.6796329021453857
Vectorized Stochastic Ricker takes:
0.002470254898071289
vectorise2.py is done

**********************************************************************

Code ran without errors

Time consumed = 0.84766s

======================================================================
Inspecting script file Girko.R...

File contents are:

**********************************************************************
# Plot Girko’s law simulation.
rm(list = ls())

require(ggplot2)
build_ellipse <- function(hradius, vradius){ # function that returns an ellipse
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}
N <- 250 # Assign size of the matrix

M <- matrix(rnorm(N * N), N, N) # Build the matrix

eigvals <- eigen(M)$values # Find the eigenvalues

eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) # Build a dataframe

my_radius <- sqrt(N) # The radius of the circle is sqrt(N)

ellDF <- build_ellipse(my_radius, my_radius) # Dataframe to plot the ellipse

names(ellDF) <- c("Real", "Imaginary") # rename the columns
# plot the eigenvalues
pdf("../results/Girko.pdf")
p <- ggplot(eigDF, aes(x = Real, y = Imaginary))
p <- p +
  geom_point(shape = I(3)) +
  theme(legend.position = "none")

# now add the vertical and horizontal line
p <- p + geom_hline(aes(yintercept = 0))
p <- p + geom_vline(aes(xintercept = 0))

# finally, add the ellipse
p <- p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))
p


**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2

======================================================================
Inspecting script file next.R...

File contents are:

**********************************************************************
# Example of next
rm(list = ls())
for (i in 1:10) {
  if ((i %% 2) == 0) # check if the number is odd
    next # pass to next iteration of loop 
  print(i)
}
**********************************************************************

Testing next.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors

Time consumed = 0.19168s

======================================================================
Inspecting script file plotLin.R...

File contents are:

**********************************************************************
# Demonstration of mathematical annotation.
rm(list = ls())
require(ggplot2)
x <- seq(0, 100, by = 0.1)
y <- -4. + 0.25 * x +
  rnorm(length(x), mean = 0., sd = 2.5)

# and put them in a dataframe
my_data <- data.frame(x = x, y = y)

# perform a linear regression
my_lm <- summary(lm(y ~ x, data = my_data))

# plot the data
pdf("../results/MyLinReg.pdf")
p <-  ggplot(my_data, aes(x = x, y = y,
                          colour = abs(my_lm$residual))
             ) +
  geom_point() +
  scale_colour_gradient(low = "black", high = "red") +
  theme(legend.position = "none") +
  scale_x_continuous(
    expression(alpha^2 * pi / beta * sqrt(Theta)))

# add the regression line
p <- p + geom_abline(
  intercept = my_lm$coefficients[1][1],
  slope = my_lm$coefficients[2][1],
  colour = "red")
# throw some math on the plot
p <- p + geom_text(aes(x = 60, y = 0,
                       label = "sqrt(alpha) * 2* pi"), 
                       parse = TRUE, size = 6, 
                       colour = "blue")
pdf("../results/MyLinReg.pdf")
print(p)
dev.off()


**********************************************************************

Testing plotLin.R...

Output (only first 500 characters): 


**********************************************************************
pdf 
  2 

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2

======================================================================
Inspecting script file Florida.R...

File contents are:

**********************************************************************
# Author: Shiyuan Huang (sh422@ic.ac.uk)
# Script: Florida.R
# Created: Nov 2022

rm(list = ls())#clear out workspace
load("../data/KeyWestAnnualMeanTemperature.RData")

View(ats)

#Plot Temperature in key west,Florida
pdf("../results/FloridaPlot1.pdf")
plot(ats, main = "Temperature in key west,Florida")
dev.off()

temp_cor <- cor(ats$Temp, ats$Year)
temp_cor

i <- length(ats$Year)
cor_of_random = c()


# generate corr coeffs from the 1000 random samples
for(n in 1:1000){
    temp_random <- sample(ats$Temp, i)
    x = cor(temp_random, ats$Year)
    cor_of_random = c(cor_of_random, x)
}

# Compare the random coefficient correaltion 
pdf("../results/FloridaPlot2.pdf")
hist(cor_of_random, xlab = "Random correlation coefficients", main = "Permutation analysis")
dev.off()

pdf("../results/FloridaPlot3.pdf")
plot(cor_of_random, ylab = "Random correlation coefficients", main = "Year ~ Temperature in Florida")
dev.off()

#Calculating p-value
pvalue = sum(cor_of_random > temp_cor) / 1000


**********************************************************************

Testing Florida.R...

Output (only first 500 characters): 


**********************************************************************
null device 
          1 
[1] 0.5331784
null device 
          1 
null device 
          1 

**********************************************************************

Code ran without errors

Time consumed = 0.34153s

======================================================================
Inspecting script file sample.R...

File contents are:

**********************************************************************
######### Functions ##########

rm(list = ls())
## A function to take a sample of size n from a population "popn" and return its mean
myexperiment <- function(popn,n) {
    pop_sample <- sample(popn, n, replace = FALSE)
    return(mean(pop_sample))
}

## Calculate means using a FOR loop on a vector without preallocation:
loopy_sample1 <- function(popn, n, num) {
    result1 <- vector() #Initialize empty vector of size 1 
    for(i in 1:num) {
        result1 <- c(result1, myexperiment(popn, n))
    }
    return(result1)
}

## To run "num" iterations of the experiment using a FOR loop on a vector with preallocation:
loopy_sample2 <- function(popn, n, num) {
    result2 <- vector(,num) #Preallocate expected size
    for(i in 1:num) {
        result2[i] <- myexperiment(popn, n)
    }
    return(result2)
}

## To run "num" iterations of the experiment using a FOR loop on a list with preallocation:
loopy_sample3 <- function(popn, n, num) {
    result3 <- vector("list", num) #Preallocate expected size
    for(i in 1:num) {
        result3[[i]] <- myexperiment(popn, n)
    }
    return(result3)
}


## To run "num" iterations of the experiment using vectorization with lapply:
lapply_sample <- function(popn, n, num) {
    result4 <- lapply(1:num, function(i) myexperiment(popn, n))
    return(result4)
}

## To run "num" iterations of the experiment using vectorization with sapply:
sapply_sample <- function(popn, n, num) {
    result5 <- sapply(1:num, function(i) myexperiment(popn, n))
    return(result5)
}

set.seed(12345)
popn <- rnorm(10000) # Generate the population
hist(popn)

n <- 100 # sample size for each experiment
num <- 10000 # Number of times to rerun the experiment

print("Using loops without preallocation on a vector took:" )
print(system.time(loopy_sample1(popn, n, num)))

print("Using loops with preallocation on a vector took:" )
print(system.time(loopy_sample2(popn, n, num)))

print("Using loops with preallocation on a list took:" )
print(system.time(loopy_sample3(popn, n, num)))

print("Using the vectorized sapply function (on a list) took:" )
print(system.time(sapply_sample(popn, n, num)))

print("Using the vectorized lapply function (on a list) took:" )
print(system.time(lapply_sample(popn, n, num)))
**********************************************************************

Testing sample.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops without preallocation on a vector took:"
   user  system elapsed 
  0.351   0.018   0.369 
[1] "Using loops with preallocation on a vector took:"
   user  system elapsed 
  0.223   0.000   0.223 
[1] "Using loops with preallocation on a list took:"
   user  system elapsed 
  0.227   0.000   0.227 
[1] "Using the vectorized sapply function (on a list) took:"
   user  system elapsed 
   0.23    0.00    0.23 
[1] "Using the vectorized lapply function (on a list) took:"
   user  syst
**********************************************************************

Code ran without errors

Time consumed = 1.61443s

======================================================================
Inspecting script file PP_Dists.R...

File contents are:

**********************************************************************
# Author: Shiyuan Huang (sh422@ic.ac.uk)
# Script: PP_Dists.R
# Created: Nov 2022

rm(list = ls())
require(dplyr)

MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")
dplyr::glimpse(MyDF)
x <- unique(MyDF$Type.of.feeding.interaction)

#convert mass from mg to g
MyDF$Prey.mass[which(MyDF$Prey.mass.unit == "mg")] <- MyDF$Prey.mass[which(MyDF$Prey.mass.unit=="mg")]/1000

#predator subplot
pdf("../results/Pred_Subplots.pdf")
par(mfcol=c(5,1))
for(i in x){
  plot(density(log(MyDF$Predator.mass[which(MyDF$Type.of.feeding.interaction==i)])),
  xlab="log(predator_mass)",ylab="density",main=i)
}
dev.off()

#prey subplot
pdf("../results/Prey_Subplots.pdf")
par(mfcol=c(5,1))
for(i in x){
    plot(density(log(MyDF$Prey.mass[which(MyDF$Type.of.feeding.interaction==i)])),
    xlab="log(prey_mass)",ylab="density",main=i)
}
dev.off()

#ratio subplot
pdf("../results/SizeRatio_Subplots.pdf")
par(mfcol=c(5,1))
for(i in x){
  ratio <- log(MyDF$Prey.mass[which(MyDF$Type.of.feeding.interaction==i)] / MyDF$Predator.mass[which(MyDF$Type.of.feeding.interaction==i)])
  plot(density(ratio),xlab="log(ratio)",ylab="density",main=i)
}
dev.off()

#pp results
results <- matrix(NA,7,5)
rownames(results) <- c("Feeding type", "Mean of log(Predator_mass)", "Median of log(Predator_mass)", 
"Mean of log(Prey_mass)", "Median of log(Prey_mass)","Mean of log(Ratio)", "Median of log(Ratio)")
results[1,] <- c("insectivorous","piscivorous","planktivorous","predacious","predacious/piscivorous")
results[2,] <- tapply(log(MyDF$Predator.mass),MyDF$Type.of.feeding.interaction, mean)
results[3,] <- tapply(log(MyDF$Predator.mass),MyDF$Type.of.feeding.interaction, median)
results[4,] <- tapply(log(MyDF$Prey.mass),MyDF$Type.of.feeding.interaction, mean)
results[5,] <- tapply(log(MyDF$Prey.mass),MyDF$Type.of.feeding.interaction, median)
results[6,] <- tapply(log(MyDF$Prey.mass/MyDF$Predator.mass),MyDF$Type.of.feeding.interaction, mean)
results[7,] <- tapply(log(MyDF$Prey.mass/MyDF$Predator.mass),MyDF$Type.of.feeding.interaction, median)
results
write.csv(results,"../results/PP_Results.csv")

**********************************************************************

Testing PP_Dists.R...

Output (only first 500 characters): 


**********************************************************************
Rows: 34,931
Columns: 15
$ Record.number               <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,…
$ In.refID                    <chr> "ATSH063", "ATSH080", "ATSH089", "ATSH143"…
$ IndividualID                <chr> "1", "2", "3", "4", "5", "6", "7", "8", "9…
$ Predator                    <chr> "Rhizoprionodon terraenovae", "Rhizopriono…
$ Predator.common.name        <chr> "Atlantic sharpnose shark", "Atlantic shar…
$ Predator.taxon              <chr> "ectotherm vertebrate", "ectotherm verte
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: dplyr

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union


======================================================================
Inspecting script file get_TreeHeight.py...

File contents are:

**********************************************************************
#!/usr/bin/env python3

"""This script is python version of get_TreeHeight.R"""

__appname__ = 'get_TreeHeight.py'
__author__ = '01_Awesome_Aardvarks'
__version__ = '0.0.1'
__license__ = 'None'

import sys
import numpy as np
import csv


def Cal_TH(degrees, distance):
    """Calculates the height of a tree given distance of each tree
    from its base and angle to its top, using the trigonometric formula"""

    radians = degrees * np.pi / 180
    height = distance * np.tan(radians)

    return height

def main(argv):
    """Main entry point of program"""
    try:
        input = sys.argv[1]
    except (FileNotFoundError, IndexError) as error:
        print("Your input is nonsense! We will work on trees.csv file.")
        input = "../data/trees.csv"

    
    Treedata = []
     
    with open(input) as f:
    # Append file to list
      mydata = csv.reader(f)

      for row in mydata:
          Treedata.append(row)

    # Add tree heights to list
    Treedata[0].append("Tree.Height.m")

    for i in range(1, len(Treedata)):
        Treedata[i].append(Cal_TH( float(Treedata[i][2]), float(Treedata[i][1]) ))
    
    path = "../results/" + input.split("/")[2].split(".")[0] + "_treeheights.csv"

    w = open(path, 'w')
    write = csv.writer(w)
    for row in Treedata:
        write.writerow(row)
          

if __name__ == '__main__':
    status = main(sys.argv)
    sys.exit(status)
**********************************************************************

Testing get_TreeHeight.py...

get_TreeHeight.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 100

Output (only first 500 characters): 


**********************************************************************
Your input is nonsense! We will work on trees.csv file.

**********************************************************************

Code ran without errors

Time consumed = 0.14571s

======================================================================
Inspecting script file TAutoCorr.tex...

File contents are:

**********************************************************************
\documentclass[12pt]{article}
\usepackage{natbib}
\usepackage{graphicx}

\title{Is annual temperatures are correlated in successive years in Florida?}
\author{01\_Awesome\_Aardvarks}
\date{\today}

\begin{document}
  \maketitle
  \section{Introduction}
  Key West is an island located in Florida. Warmer temperatures in Key West can result in less dissolved oxygen in water which may associated with fish dying. Higher temperatures can increasing risk of coral bleaching as well\citep{climatechange}. \par
  \vspace{5mm}
  \noindent In this study, we analyzed whether the temperature in one year is significantly correlated with the next year(successive year), across years in Key West.
  \section{Materials \& Methods}
  \subsection{Computing Tools}
  We use the R language because the R language is convenient in the processing of data frame, and the ability to analyze small dataset (here the data has 100 observations) is excellent. The operating system is Ubuntu 22.04.
  \subsection{Data}
  The data recorded the temperatures in Florida from 1900 to 2000. The scatter plot between temperature and year is shown in Figure \ref{fig:1}. Here we show some of the data.
  \begin{verbatim}
    > str(ats)
      'data.frame':   100 obs. of  2 variables:
      $ Year: int  1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 ...
      $ Temp: num  23.8 24.7 24.7 24.5 24.9 ...
  \end{verbatim}

  \begin{figure}[htb]
    \includegraphics[width=\linewidth]{../results/TAutoCorrPlot1.pdf}
    \caption{The scatter plot between temperatures and years.}
    \label{fig:1}
  \end{figure}

 \subsection{Permutation Analysis}
 A permutation test (also called re-randomization test) is an exact statistical hypothesis test making use of the proof by contradiction. The properties of random permutations were proved by \cite{hemerik_exact_2018} through the Conditional Monte Carlo test they proposed.\par
 \vspace{5mm}
 The test statistic is the correlation coefficient between temperature and successive years. The null hypothesis here is the temperature of one year isn't correlated with the next year across years in Florida. The alternative hypothesis here is temperature of one year is correlated with the next year across years in Florida. We did 10000 times shuffles of successive years. 
 \subsection{Estimation of p-value}
 Instead of standard p-value calculation, we calculated the estimation of p-value in equation \ref{equ:1} for a correlation coefficient, because measurements of climatic variables in successive time-points in a time series (successive seconds, minutes, hours, months, years, etc.) are not independent.
 \begin{equation}\label{equ:1}
  estimated\_p = \frac{\sum{(cor\_of\_random \ge temp\_cor)}}{length(cor\_of\_random)}
 \end{equation}
 \section{Results \& Discussion}
 The estimated p-value after 10000 times shuffles is around $1 \times 10 ^{-4}$ which is much less than 0.05. This p-value supports the alternative hypothesis and rejects the null hypothesis.\par
 \vspace{5mm}
 \noindent The distribution of the random correlation coefficients is shown in Figure \ref{fig:2}. The red line in Figure \ref{fig:2} is the observed Pearson correlation coefficient $r$ before shuffling the successive years. The observed $r$ is larger compared to the distribution of possible $r$. In other words, when the empirical value is very far from the permutation results, we can be pretty sure that: when the variables are truly independent, a $r$ as strong as the observed $r$ is unlikely to appear in a situation of pure chance. \par
 \vspace{5mm}
 \begin{figure}[htb]
  \includegraphics[width=\linewidth]{../results/TAutoCorrPlot2.pdf}
  \caption{Correlation coefficients after permutation.}
  \label{fig:2}
 \end{figure}


  \clearpage
  \bibliographystyle{agsm}

  \bibliography{TAutoCorr}

\end{document}
**********************************************************************

Testing TAutoCorr.tex...

======================================================================
Inspecting script file try.R...

File contents are:

**********************************************************************
# Example of how to use try function

rm(list = ls())

doit <- function(x) {
    temp_x <- sample(x, replace = TRUE)
    if (length(unique(temp_x)) > 30) {#only take mean if sample was sufficient
         print(paste("Mean of this sample was:", as.character(mean(temp_x))))
    } 
    else {
        stop("Couldn't calculate mean: too few unique values!")
        }
    }

set.seed(1345) # again, to get the same result for illustration

popn <- rnorm(50)

hist(popn)

result <- lapply(1:15, function(i) try(doit(popn), FALSE))
result

result <- vector("list", 15) # Preallocate/Initialize
for(i in 1:15) {
    result[[i]] <- try(doit(popn), FALSE)
    }



**********************************************************************

Testing try.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Mean of this sample was: -0.11620822588674"
[1] "Mean of this sample was: -0.0468516755995931"
[1] "Mean of this sample was: -0.0890228211466614"
[1] "Mean of this sample was: -0.124229742255296"
[1] "Mean of this sample was: 0.0314144452816157"
[1] "Mean of this sample was: -0.233476945796405"
[1] "Mean of this sample was: -0.196681538928001"
[1] "Mean of this sample was: 0.0146969612111605"
[1] "Mean of this sample was: -0.234913159471725"
[1] "Mean of this sample was: -0.0497464588165691"
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!

======================================================================
Inspecting script file MyBars.R...

File contents are:

**********************************************************************
# This script demonstrates how to annotate a diagram 
# and save the resulting diagram to the results directory
rm(list = ls())
require(ggplot2)
a <- read.table("../data/Results.txt", header = TRUE)
head(a)
a$ymin <- rep(0, dim(a)[1]) # append a column of zeros

# Print the first linerange
pdf("../results/MyBars.pdf")
p <- ggplot(a)
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y1,
                          size = (0.5)
                          ),
                        colour = "#E69F00",
                        alpha = 1/2, show.legend = FALSE)

# Print the second linerange
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y2,
                          size = (0.5)
                          ),
                        colour = "#56B4E9",
                        alpha = 1/2, show.legend = FALSE)

# Print the third linerange:
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y3,
                          size = (0.5)
                          ),
                        colour = "#D55E00",
                        alpha = 1/2, show.legend = FALSE)

# Annotate the plot with labels:
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",
                            breaks = seq(3, 5, by = 0.05)) + 
                            scale_y_continuous("My y axis") + 
                            theme_bw() + 
                            theme(legend.position = "none") 
p
graphics.off()


**********************************************************************

Testing MyBars.R...

Output (only first 500 characters): 


**********************************************************************
         x   y1   y2 y3 Label
1 3.515424 4320 4320  0  <NA>
2 3.533984 2160 2160  0  <NA>
3 3.557647 4320 4320  0  <NA>
4 3.569953 4320 4320  0  <NA>
5 3.578984 8640 8640  0  <NA>
6 3.585665 2160 2160  0  <NA>

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2
Warning message:
Removed 91 rows containing missing values (geom_text). 

======================================================================
Inspecting script file PP_Regress_loc.R...

File contents are:

**********************************************************************
# Author: 01_Awesome_Aardvarks
# Script: PP_Regress_loc.R
# Date: Dec 2022
# Desc: 
# Do the same thing as PP_Regress.R, but the analysis this time
# should be separate by the dataset’s Location field.

rm(list=ls())  #empty the all variables

#1a. load package
require(tidyverse)

#1b. import dataset
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")

#------------------------------------
##calculating regression statistic
#2a.
for (i in 1:nrow(MyDF)){
    if(MyDF$Prey.mass.unit[i] == "mg"){
        MyDF$Prey.mass.unit[i] <- "g"   # chenge with mg to g
        MyDF$Prey.mass[i] <- MyDF$Prey.mass[i] / 1000 # change the number correctly
    }
}

#2b. Feeding, lifestage and location subgroups
FLL_groups <- MyDF %>% group_by(Type.of.feeding.interaction,Predator.lifestage,Location) %>% count()

#2c. running linear model
linear_models <- MyDF %>% 
  group_by(Type.of.feeding.interaction,Predator.lifestage,Location) %>%
  do(model = lm(Predator.mass ~ Prey.mass, data= .))

#2d. creating table
FLL_stats <- data.frame(Feeding_Type = FLL_groups$Type.of.feeding.interaction,
                        Predator_Lifestage=FLL_groups$Predator.lifestage,
                        Location =FLL_groups$Location,
                        Intercept=NA,Slope=NA,P_value_overall=NA, R_squared=NA,
                        F_statistic=NA)

#2e. excluding rows with sample size of 5 or less
  #too few data points for accurate sample size
#examining rows to exclude
FLL_groups[FLL_groups$n <= 5,]
#   Type.of.feeding.interaction Predator.lifestage Location                n
# 1 piscivorous                 postlarva/juvenile Antarctic Peninsula     2
# 2 planktivorous               juvenile           Gulf of Alaska          2
# 3 predacious                  adult              Gulf of Maine, New England     5
#row numbers of rows to exclude
which(FLL_groups$n <= 5,) #21 24 36
#row numbers of rows to include - to calculate statistics for
i_values <- c(1:nrow(FLL_groups))[-which(FLL_groups$n <= 5,)]

#2f. combining results into table
for (i in i_values){
#for (i in c(1:20,22:23,25:35,37:nrow(FLL_groups))){
  #browser()
  FLL_stats[i,"Intercept"] <- summary(linear_models$model[[i]])$coef[1,1] #Intercept
  FLL_stats[i,"Slope"] <- summary(linear_models$model[[i]])$coef[2,1]  # slope
  FLL_stats[i,"P_value_overall"] <- summary(linear_models$model[[i]])$coef[2,4]  #p value, slope significance
  FLL_stats[i,"R_squared"] <- summary(linear_models$model[[i]])$r.squared #r squared
  FLL_stats[i,"F_statistic"] <- summary(linear_models$model[[i]])$fstatistic[[1]] #f statistic
}

#2g. making results csv 
write.csv(FLL_stats, "../results/PP_Regress_loc_Results.csv")


print("Script complete!")
**********************************************************************

Testing PP_Regress_loc.R...

Output (only first 500 characters): 


**********************************************************************
# A tibble: 3 x 4
# Groups:   Type.of.feeding.interaction, Predator.lifestage, Location [3]
  Type.of.feeding.interaction Predator.lifestage Location                      n
  <chr>                       <chr>              <chr>                     <int>
1 piscivorous                 postlarva/juvenile Antarctic Peninsula           2
2 planktivorous               juvenile           Gulf of Alaska                2
3 predacious                  adult              Gulf of Maine, New Engla…     5
[1] 
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
Warning messages:
1: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
2: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
3: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
4: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
5: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
6: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
7: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
8: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
9: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable
10: In summary.lm(linear_models$model[[i]]) :
  essentially perfect fit: summary may be unreliable

======================================================================
Inspecting script file control_flow.R...

File contents are:

**********************************************************************
rm(list = ls())

### if statements ###
a <- TRUE
if (a == TRUE) {
    print ("a is TRUE")
} else {
    print ("a is FALSE")
}
z <- runif(1) ## Generate a uniformly distributed random number
if (z <= 0.5) {print ("Less than a half")}

for (i in 1:10) {
    j <- i * i
    print(paste(i, " squared is", j ))
}

for(species in c('Heliodoxa rubinoides', 
                 'Boissonneaua jardini', 
                 'Sula nebouxii')) {
      print(paste('The species is', species))
}

v1 <- c("a","bc","def")
for (i in v1) {
    print(i)
}

i <- 0
while (i < 10) {
    i <- i+1
    print(i^2)
}
**********************************************************************

Testing control_flow.R...

Output (only first 500 characters): 


**********************************************************************
[1] "a is TRUE"
[1] "Less than a half"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "The species is Heliodoxa rubinoides"
[1] "The species is Boissonneaua jardini"
[1] "The species is Sula nebouxii"
[1] "a"
[1] "bc"
[1] "def"
[1] 1
[1] 4
[1] 9
[1] 16
[1] 25
[1] 36
[1] 49
[1] 64
[1] 81
[1] 100

**********************************************************************

Code ran without errors

Time consumed = 0.20091s

======================================================================
Inspecting script file TAutoCorr.bib...

File contents are:

**********************************************************************
@article{hemerik_exact_2018,
	title = {Exact testing with random permutations},
	volume = {27},
	issn = {1133-0686, 1863-8260},
	url = {http://link.springer.com/10.1007/s11749-017-0571-1},
	doi = {10.1007/s11749-017-0571-1},
	pages = {811--825},
	number = {4},
	journaltitle = {{TEST}},
	shortjournal = {{TEST}},
	author = {Hemerik, Jesse and Goeman, Jelle},
	urldate = {2022-12-08},
	date = {2018-12},
	langid = {english},
	year = {2018}
}


@Inbook{climatechange,
author="Interdepartmental Climate Change Group",
title="Temperature and Evapotranspiration",
bookTitle="Climate Change and Water Management in South Florida",
year="2009",
pages="13--14",
}
**********************************************************************

Testing TAutoCorr.bib...

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:

**********************************************************************
# Author: 01_Awesome_Aardvarks
# Script: TAutoCorr.R
# Date: Dec 2022
# Desc:
# Groupwork Practical: Autocorrelation in Florida weather
# Are temperatures of one year significantly correlated with
# the next year (successive years), across years in Florida?

rm(list = ls())

require(ggplot2)

# view the data
load("../data/KeyWestAnnualMeanTemperature.RData")
pdf("../results/TAutoCorrPlot1.pdf")
plot(ats, main = "Temperature in Florida between 1990-2000")
dev.off()

# permutation test
# test statistic: correlation coefficient between year and temperature
# null hypothesis: Temperatures of one year isn't correlated with the next year across years in Florida
# alternative htpothesis: Temperatures of one year is correlated with the next year across years in Florida
# permutation set: 10000 shuffles of ats$Temp

n <- length(ats$Year) # the total number of years

# get the temperature of successive years
temp_1 <- c(ats[1:(n - 1), 2]) # temperature from year 1 to year 99
temp_2 <- c(ats[2:n, 2]) # temperature from year 2 to year 100

# calculate the correlation between temp_1 and temp_2
temp_cor <- cor(temp_1, temp_2) 

# starting shuffling
cor_of_random <- c()
N <- 10000
# apply the loop to reach as many as time to see the most results
for (i in 1:N) {
    random_sample <- sample(ats$Temp, n, replace = F) 
    temp_1 <- random_sample[1:(n - 1)]
    temp_2 <- random_sample[2:n]
    cr <- cor(temp_1, temp_2)
    cor_of_random <- c(cor_of_random, cr)
}


pdf("../results/TAutoCorrplot2.pdf")
# show the distribution of two parameters'correlation through 10000 times
hist(cor_of_random,
     xlab = "Random correlation coefficients",
     main = "Histogram of Random Correlation Coefficients")
abline(v=temp_cor, col="red")
dev.off()

# hint: you can’t use the standard p-value calculated for a correlation coefficient, 
# because measurements of climatic variables in successive time-points in a time series 
# (successive seconds, minutes, hours, months, years, etc.) are not independent.
estimated_p <- sum(cor_of_random[cor_of_random >= temp_cor]) / length(cor_of_random)

print(paste("The estimated p-value is: ", estimated_p))
# [1] "The estimated p-value is:  0.000108006045209073"
# p-value < 0.05, reject null hypothesis, accept alternative htpothesis

# Results: Temperatures of one year is correlated with the next year across years in Florida
**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 


**********************************************************************
null device 
          1 
null device 
          1 
[1] "The estimated p-value is:  0.000102361988432889"

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2

======================================================================
Inspecting script file Ricker.R...

File contents are:

**********************************************************************
# Runs the Ricker model.

rm(list = ls())
Ricker <- function(N0=1, r=1, K=10, generations=50)
{
  # Runs a simulation of the Ricker model
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations)
  {
    N[t] <- N[t-1] * exp(r*(1.0-(N[t-1]/K)))
  }
  return (N)
}

plot(Ricker(generations=10), type="l")
**********************************************************************

Testing Ricker.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.23299s

======================================================================
Inspecting script file boilerplate.R...

File contents are:

**********************************************************************
# R scripts for demonstrating R functions.

rm(list = ls())

MyFunction <- function(Arg1, Arg2) {
  
  # Statements involving Arg1, Arg2:
  print(paste("Argument", as.character(Arg1), "is a", class(Arg1))) # print Arg1's type
  print(paste("Argument", as.character(Arg2), "is a", class(Arg2))) # print Arg2's type
    
  return(c(Arg1, Arg2)) #this is optional, but very useful
}

MyFunction(1, 2) #test the function
MyFunction("Riki", "Tiki") #A different test
**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Code ran without errors

Time consumed = 0.19752s

======================================================================
Inspecting script file run_vectorized.sh...

File contents are:

**********************************************************************
#!/bin/sh
# Author: 01_Awesome_Aardvarks
# Script: run_vectorized.sh
# Desc: run the R and python version of vectorize1 and vectorize2
# Arguments: none
# Date: Dec 2022

echo " output of Vectorize1.R"
Rscript Vectorize1.R

echo " output of Vectorize2.R"
Rscript Vectorize2.R

echo " output of Vectorize1.py"
python3 Vectorize1.py

echo "output of Vectorize2.py"
python3 Vectorize2.py

echo "finish the run time output"
**********************************************************************

Testing run_vectorized.sh...

Output (only first 500 characters): 


**********************************************************************
 output of Vectorize1.R
[1] "Using loops, the time taken is:"
   user  system elapsed 
  0.071   0.000   0.071 
[1] "Using the in-built vectorized function, the time taken is:"
   user  system elapsed 
  0.001   0.000   0.001 
 output of Vectorize2.R
[1] "Time of stochrick took:"
   user  system elapsed 
  0.210   0.015   0.225 
[1] "Time of stochrickvect took:"
   user  system elapsed 
  0.015   0.000   0.015 
 output of Vectorize1.py
after the loop, time is: 0.4561786651611328
after the vectori
**********************************************************************

Code ran without errors

Time consumed = 2.21068s

======================================================================
Inspecting script file R_conditionals.R...

File contents are:

**********************************************************************
# Examples of funtions with conditionals

rm(list = ls())
# Checks if an integer is even
is.even <- function(n = 2) {
  if (n %% 2 == 0) {
    return(paste(n,'is even!'))
  } else {
  return(paste(n,'is odd!'))
  }
}

is.even(6)

# Checks if a number is a power of 2
is.power2 <- function(n = 2) {
  if (log2(n) %% 1==0) {
    return(paste(n, 'is a power of 2!'))
  } else {
  return(paste(n,'is not a power of 2!'))
    }
}

is.power2(4)

# Checks if a number is prime
is.prime <- function(n) {
  if (n==0) {
    return(paste(n,'is a zero!'))
  } else if (n==1) {
    return(paste(n,'is just a unit!'))
  }
    
  ints <- 2:(n-1)
  
  if (all(n%%ints!=0)) {
    return(paste(n,'is a prime!'))
  } else {
  return(paste(n,'is a composite!'))
    }
}

is.prime(3)
**********************************************************************

Testing R_conditionals.R...

Output (only first 500 characters): 


**********************************************************************
[1] "6 is even!"
[1] "4 is a power of 2!"
[1] "3 is a prime!"

**********************************************************************

Code ran without errors

Time consumed = 0.18142s

======================================================================
Inspecting script file Vectorize1.py...

File contents are:

**********************************************************************
#!/usr/bin/env python3

""" This script is the transfered version of Vectorise1.R"""

__appname__ = 'Vectorize1'
__author__ = '01_Awesome_Aardvarks'
__version__ = '0.0.1'
__license__ = 'None'

import numpy as np
import time
#create the random matrix
T = np.mat(np.random.randint(1000000,size=(1000,1000)))


def sumallelements(T):
    """Paremeters:
    T(matrix): the given matrix
    Returns:
        sum(float): sum all elements in M
    """
    dimension = T.shape
    Sum = 0
    for i in range(0,dimension[0]): #loop rows
        for j in range(0,dimension[1]): # loop columns
                Sum = Sum + T[i,j]
    return Sum

# time sumallelements
start = time.time()
sumallelements(T)  
end = time.time()
print("after the loop, time is:", end-start) 

# time sum function in numpy
start = time.time()
np.sum(T) # vectorized function
end = time.time()
print("after the vectorized function in numpy, the time is:", end - start)

print("vectorise1.py is done")
**********************************************************************

Testing Vectorize1.py...

Vectorize1.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 100

Output (only first 500 characters): 


**********************************************************************
after the loop, time is: 0.4745619297027588
after the vectorized function in numpy, the time is: 0.0006601810455322266
vectorise1.py is done

**********************************************************************

Code ran without errors

Time consumed = 0.63707s

======================================================================
Inspecting script file browse.R...

File contents are:

**********************************************************************
rm(list = ls())

Exponential <- function(N0 = 1, r = 1, generations = 10) {
  # Runs a simulation of exponential growth
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations) {
    N[t] <- N[t - 1] * exp(r)
    browser()
  }
  return(N)
}

plot(Exponential(), type = "l", main = "Exponential growth")
**********************************************************************

Testing browse.R...

Output (only first 500 characters): 


**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors

Time consumed = 0.23796s

======================================================================
Inspecting script file GPDD_Data.R...

File contents are:

**********************************************************************
# Author: Shiyuan Huang (sh422@ic.ac.uk)
# Script: GPDD_Data.R
# Created: Nov 2022

rm(list = ls())
library(maps)
load("../data/GPDDFiltered.RData")

# set this map
map(database = "world", fill = TRUE, col = "black")
# set the points on the map.
points(x = gpdd$long, y = gpdd$lat, pch = 20, col = "red")


## The sites are not evenly distributed,
## and most of these data points are located on the west coast of North America and Europe.

**********************************************************************

Testing GPDD_Data.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.46796s

======================================================================
Inspecting script file PP_Regress.R...

File contents are:

**********************************************************************
# Author: Shiyuan Huang (sh422@ic.ac.uk)
# Script: PP_Regress.R
# Created: Nov 2022

rm(list = ls())
require(ggplot2)
require(dplyr)
library(broom)

MyDF = read.csv("../data/EcolArchives-E089-51-D1.csv")

#convert mass from mg to g
MyDF$Prey.mass[which(MyDF$Prey.mass.unit == "mg")] <- MyDF$Prey.mass[which(MyDF$Prey.mass.unit=="mg")]/1000

# plot predator mass against prey mass by type of feeding and predator lifestage
pdf("../results/PP_Regress_Plots.pdf")
p = ggplot(MyDF, aes(x = Prey.mass, y = Predator.mass, colour = Predator.lifestage)) + 
    geom_smooth(method = "lm", fullrange = TRUE, size = 0.7) + 
    geom_point(size = 0.5, pch = 3) + 
    facet_wrap( Type.of.feeding.interaction ~ ., ncol = 1) +
    scale_x_log10() + scale_y_log10() + 
    theme(legend.position = "bottom", aspect.ratio = 0.5) +
    guides(color = guide_legend(nrow = 1))
print(p)
graphics.off()

#linear regression
MyDF$Type.of.feeding.interaction <- as.factor(MyDF$Type.of.feeding.interaction)
MyDF$Predator.lifestage <- as.factor(MyDF$Predator.lifestage)

mydf1 =  MyDF %>% 
        group_by(Type.of.feeding.interaction, Predator.lifestage) %>%
        do(glance(lm(Predator.mass ~ Prey.mass, data = .)))
mydf2 =  MyDF %>% 
        group_by(Type.of.feeding.interaction, Predator.lifestage) %>%
        do(tidy(lm(Predator.mass ~ Prey.mass, data = .)))

x = seq(1:length(mydf2$estimate)) # Generate even and odd number subset as the index of slope and intercept
even = subset(x, x %% 2 == 0)
odd = subset(x, x %% 2 == 1)

output <- data.frame(
mydf1$Type.of.feeding.interaction,
mydf1$Predator.lifestage,
slope = mydf2$estimate[even],
intercept = mydf2$estimate[odd],
R.squared = mydf1$adj.r.squared,
F.value = mydf1$statistic,
p.value = mydf1$p.value
)

write.csv(output, "../results/PP_Regress_Results.csv", row.names = F)
**********************************************************************

Testing PP_Regress.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: ggplot2
Loading required package: dplyr

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

`geom_smooth()` using formula 'y ~ x'
Warning messages:
1: In qt((1 - level)/2, df) : NaNs produced
2: In max(ids, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf

======================================================================
Inspecting script file get_TreeHeight.R...

File contents are:

**********************************************************************
# Author: 01_Awesome_Aardvarks
# Script: get_TreeHeight.R
# Date: Dec 2022
# Desc: 
# Function to calculate tree height and strip the .csv

#Function to calculate tree height and strip the .csv
Cal_TH <- function(degrees, distance) {
    radians <- degrees * pi / 180
    height <- distance * tan(radians)
    
    return(height)
}

#By creating an interactive interface, R programs can be run on LInux with command line parameters
args <- commandArgs(trailingOnly = TRUE)

output <- gsub("/|../data/|.csv","",args) #Remove file extension and relative path



Treedata <- read.csv(args)
Treedata$Tree.Height.m <- Cal_TH(Treedata$Angle.degrees, Treedata$Distance.m)

#put the result into a file in results folder
write.csv(Treedata, paste("../results/", output, "_treeheights.csv", sep = ""), row.names = FALSE)
**********************************************************************

Testing get_TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Error in file(file, "rt") : invalid 'description' argument
Calls: read.csv -> read.table -> file
Execution halted

======================================================================
Inspecting script file Vectorize2.R...

File contents are:

**********************************************************************
# Author: Shiyuan Huang (sh422@ic.ac.uk)
# Script: Vectorize2.R
# Created: Oct 2022

# Runs the stochastic Ricker equation with gaussian fluctuations

rm(list = ls())

stochrick <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2,numyears = 100) {

  N <- matrix(NA, numyears, length(p0))  #initialize empty matrix

  N[1, ] <- p0

  for (pop in 1:length(p0)) { #loop through the populations

    for (yr in 2:numyears){ #for each pop, loop through the years

      N[yr, pop] <- N[yr-1, pop] * exp(r * (1 - N[yr - 1, pop] / K) + rnorm(1, 0, sigma)) # add one fluctuation from normal distribution
    
     }
  
  }
 return(N)

}
print("Time of stochrick took:")
print(system.time(stochrick()))

# Now write another function called stochrickvect that vectorizes the above to
# the extent possible, with improved performance: 

stochrickvect <- function(p0 = runif(1000, .5, 1.5), r = 1.2, K = 1, sigma = 0.2, numyears = 100) { 

N <- matrix(NA, numyears, length(p0))

N[1, ] <- p0
for(yr in 2:numyears){

  N[yr, ] <- N[yr - 1, ] * exp(r * (1 - N[yr - 1, ] / K) + rnorm(length(p0), 0, sigma))
}

return(N)

}
print("Time of stochrickvect took:")
print(system.time(stochrickvect()))
**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Time of stochrick took:"
   user  system elapsed 
  0.314   0.026   0.340 
[1] "Time of stochrickvect took:"
   user  system elapsed 
  0.019   0.000   0.019 

**********************************************************************

Code ran without errors

Time consumed = 0.61360s

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:

**********************************************************************
# Author: Shiyuan Huang (sh422@ic.ac.uk)
# Script: DataWrangTidy.R
# Created: Nov 2022


################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
rm(list = ls())
require(tidyverse)
MyData <- as.matrix(read.csv("../data/PoundHillData.csv", header = FALSE))

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")
MyData
############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)
############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = FALSE) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############

MyWrangledData=gather(TempData,key="Species",value="Count",-Cultivation,-Block,-Plot,-Quadrat)


MyWrangledData <- MyWrangledData %>%
                  mutate(across(c(Cultivation, Block, Plot, Quadrat), as.factor))

MyWrangledData <- MyWrangledData %>%
                  mutate(across(c(Count), as.numeric))
############# Exploring the data (extend the script below)  ###############

tidyverse_packages(include_self = TRUE) # the include_self = TRUE means list "tidyverse" as well 
MyWrangledData <- dplyr::as_tibble(MyWrangledData) 
MyWrangledData

glimpse(MyWrangledData) #like str(), but nicer!
filter(MyWrangledData, Count>100) #like subset(), but nicer!
slice(MyWrangledData, 10:15) # Look at a particular range of data rows


**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 


**********************************************************************
      V1                           V2        V3        V4        V5       
 [1,] "Cultivation"                "october" "october" "october" "october"
 [2,] "Block"                      "a"       "a"       "a"       "a"      
 [3,] "Plot"                       "1"       "1"       "1"       "1"      
 [4,] "Quadrat"                    "Q1"      "Q2"      "Q3"      "Q4"     
 [5,] "Achillea millefolium"       "4"       "8"       "3"       "20"     
 [6,] "Agrostis gigantea"          ""        ""    
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.6     ✔ purrr   0.3.4
✔ tibble  3.1.1     ✔ dplyr   1.0.6
✔ tidyr   1.1.3     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()

======================================================================
Inspecting script file preallocate.R...

File contents are:

**********************************************************************
# How pre-allocation speeds up the cycle of resizing vectors
rm(list = ls())
NoPreallocFun <- function(x) {
    a <- vector() # empty vector
    for (i in 1:x) {
        a <- c(a, i) # concatenate
        print(a)
        print(object.size(a))
    }
}

system.time(NoPreallocFun(10))

PreallocFun <- function(x) {
    a <- rep(NA, x) # pre-allocated vector
    for (i in 1:x) {
        a[i] <- i # assign
        print(a)
        print(object.size(a))
    }
}

system.time(PreallocFun(10))
**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
56 bytes
[1] 1 2
56 bytes
[1] 1 2 3
64 bytes
[1] 1 2 3 4
64 bytes
[1] 1 2 3 4 5
80 bytes
[1] 1 2 3 4 5 6
80 bytes
[1] 1 2 3 4 5 6 7
80 bytes
[1] 1 2 3 4 5 6 7 8
80 bytes
[1] 1 2 3 4 5 6 7 8 9
96 bytes
 [1]  1  2  3  4  5  6  7  8  9 10
96 bytes
   user  system elapsed 
  0.018   0.000   0.019 
 [1]  1 NA NA NA NA NA NA NA NA NA
96 bytes
 [1]  1  2 NA NA NA NA NA NA NA NA
96 bytes
 [1]  1  2  3 NA NA NA NA NA NA NA
96 bytes
 [1]  1  2  3  4 NA NA NA NA NA NA
96 bytes
 [1]  1  2  3  4  5 NA N
**********************************************************************

Code ran without errors

Time consumed = 0.32955s

======================================================================
Inspecting script file break.R...

File contents are:

**********************************************************************
# R loop demonstration.

rm(list = ls())
i <- 0 #Initialize i
    while (i < Inf) {
        if (i == 10) {
            break 
        } else { # Break out of the while loop!  
            cat("i equals " , i , " \n")
            i <- i + 1 # Update i
    }
}
**********************************************************************

Testing break.R...

Output (only first 500 characters): 


**********************************************************************
i equals  0  
i equals  1  
i equals  2  
i equals  3  
i equals  4  
i equals  5  
i equals  6  
i equals  7  
i equals  8  
i equals  9  

**********************************************************************

Code ran without errors

Time consumed = 0.21764s

======================================================================
Inspecting script file run_get_TreeHeight.sh...

File contents are:

**********************************************************************
#!/bin/sh
# Author: 01_Awesome_Aardvarks
# Script: run_get_TreeHeight.sh
# Description: runs get_TreeHeight.R and get_TreeHeight.py using tree.csv as an argument
# Arguments: None
# Date: Dec 2022

# test the R script
Rscript get_TreeHeight.R ../data/trees.csv

# test the python script
python3 get_TreeHeight.py ../data/trees.csv
**********************************************************************

Testing run_get_TreeHeight.sh...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.38229s

======================================================================
Inspecting script file DataWrang.R...

File contents are:

**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

rm(list = ls())
############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv", header = FALSE))

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv", header = TRUE, sep = ";")

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)
fix(MyData) #you can also do this
fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,], stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package

?melt #check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############

require(tidyverse)
tidyverse_packages(include_self = TRUE) # the include_self = TRUE means list "tidyverse" as well 
MyWrangledData <- dplyr::as_tibble(MyWrangledData) 
MyWrangledData
class(MyWrangledData)
glimpse(MyWrangledData) #like str(), but nicer!
filter(MyWrangledData, Count>100) #like subset(), but nicer!
slice(MyWrangledData, 10:15) # Look at a particular range of data rows
aggregate(MyWrangledData$Count, list(MyWrangledData$Species), FUN=mean) 

**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 


**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Code ran without errors

Time consumed = 10.01046s

======================================================================
Inspecting script file Florida.tex...

File contents are:

**********************************************************************
\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{float}

\title{Is Florida getting warming?}

\author{Shiyuan Huang}

\date{\today}

\begin{document}
  \maketitle

  \section{Introduction}
    This article investigated whether the tempearture in Florida correlated with time for successive years. 
    The null hypothesis is tempearture in Florida do not significantly correlate with time for successive year. The alternative hypothesis is tempearture correlates with time in Florida.

    However, using the standard p-values calculated for the correlation coefficients is not good because successive points in time in a time series are not independent of the measurement of the climate variables.
    Therefore permutation analysis by generating a distribution of random correlation coefficients and comparing observed coefficients with this random distribution.

  \section{Results}
    To determine if there was a positive correlation between year and temperature in Florida ,the correlation coefficient of 0.5331784 was obtained for the temperature data in 20th century.
    Then 1000 shuffled populations were analysed in permutations to calculate the fraction of the random correlation coefficients were greater than the observed one to determine an approximate, asymptotic,  p-value. Which is 0.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{../results/FloridaPlot1.pdf}
    \caption{Temperature over time}
    \end{figure}
        
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{../results/FloridaPlot3.pdf}
    \caption{Random Correalation Coefficients}
    \end{figure}
        
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{../results/FloridaPlot2.pdf}
    \caption{Histogram of Random Correlation Coefficients}
    \end{figure}

\section{Discussion}
We found that the p-value is below 0.05, then reject the null hypothesis "Tempearture in Florida do not significantly correlate with time for successive year". We can say the positive correlation shown between year and temperature in Florida is statistically significant.
These results suggest that temperatures in Florida increased throughout the 20th century.

\end{document}
**********************************************************************

Testing Florida.tex...

======================================================================
Inspecting script file TreeHeight.R...

File contents are:

**********************************************************************
# Author: Shiyuan Huang (sh422@ic.ac.uk)
# Script: TreeHeight.R
# Created: Nov 2022

# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula 
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"
rm(list = ls())

MyData = read.csv("../data/trees.csv", header = TRUE)
head(MyData)

Cal_TH <- function(degrees, distance) {
    radians <- degrees * pi / 180
    height <- distance * tan(radians)
    print(paste("Tree height is:", height))
  
    return (height)
}



treehight <- Cal_TH(MyData$Angle.degrees,MyData$Distance.m)
TH <- data.frame(MyData$Species,MyData$Distance.m,MyData$Angle.degrees,treehight)
names(TH) = c("Species","Distance.m","Angle.degrees","treehight")


write.csv(TH, file = "../results/TreeHts.csv", row.names =  FALSE)

**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************
             Species Distance.m Angle.degrees
1    Populus tremula   31.66583      41.28264
2      Quercus robur   45.98499      44.53592
3      Ginkgo biloba   31.24177      25.14626
4 Fraxinus excelsior   34.61667      23.33613
5     Betula pendula   45.46617      38.34913
6     Betula pendula   48.79550      33.59231
  [1] "Tree height is: 27.8021161438536" "Tree height is: 45.2460250644405"
  [3] "Tree height is: 14.6654828109493" "Tree height is: 14.9341751666304"
  [5] "Tree height is: 35.9
**********************************************************************

Code ran without errors

Time consumed = 0.21321s

======================================================================
Inspecting script file basic_io.R...

File contents are:

**********************************************************************
# A simple script to illustrate R input-output.  
# Run line by line and check inputs outputs to understand what is happening  

rm(list = ls())

MyData <- read.csv("../data/trees.csv", header = TRUE) # import with headers

write.csv(MyData, "../results/MyData.csv") #write it out as a new file

write.table(MyData[1,], file = "../results/MyData.csv", append = TRUE) # Append to it

write.csv(MyData, "../results/MyData.csv", row.names = TRUE) # write row names

write.table(MyData, "../results/MyData.csv", col.names = FALSE) # ignore column names






**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Warning message:
In write.table(MyData[1, ], file = "../results/MyData.csv", append = TRUE) :
  appending column names to file

======================================================================
Inspecting script file Vectorize1.R...

File contents are:

**********************************************************************
# The script compares the speed between vectorised and non-vectorised functions.

rm(list = ls())
M <- matrix(runif(1000000),1000,1000)

SumAllElement <- function(M){
    Dimensions <- dim(M)
    Tot <- 0
    for (i in 1:Dimensions[1]){
        for (j in 1:Dimensions[2]){
            Tot <- Tot + M[i,j]
        }
    }
    return (Tot)
}

print("Using loops, the time taken is:")
print(system.time(SumAllElement(M)))

print("Using the in-built vectorized function, the time taken is:")
print(system.time(sum(M)))

**********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops, the time taken is:"
   user  system elapsed 
  0.089   0.000   0.089 
[1] "Using the in-built vectorized function, the time taken is:"
   user  system elapsed 
  0.001   0.000   0.001 

**********************************************************************

Code ran without errors

Time consumed = 0.38633s

======================================================================
======================================================================
Finished running scripts

Ran into 11 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 100

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!